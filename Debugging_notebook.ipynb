{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_geometric.transforms as T\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torch_geometric.loader.link_neighbor_loader import LinkNeighborLoader\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "import torch.functional as F\n",
    "import torch\n",
    "import pickle \n",
    "#from gat_dependency.GAT_model import HeteroData_GNNmodel\n",
    "from gat_dependency.HetGNN_Model_Jovana import HeteroData_GNNmodel\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from torch_geometric.explain import Explainer, GNNExplainer, ModelConfig\n",
    "from torch_geometric import seed_everything\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  gene={\n",
       "    node_id=[14034],\n",
       "    names=[14034],\n",
       "    x=[14034, 3438],\n",
       "  },\n",
       "  cell={\n",
       "    node_id=[37],\n",
       "    names=[37],\n",
       "    x=[37, 1218],\n",
       "  },\n",
       "  (gene, interacts_with, gene)={ edge_index=[2, 278974] },\n",
       "  (gene, dependency_of, cell)={ edge_index=[2, 14099] },\n",
       "  (gene, rev_interacts_with, gene)={ edge_index=[2, 278974] },\n",
       "  (cell, rev_dependency_of, gene)={ edge_index=[2, 14099] }\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heterodata_obj = torch.load('Data/multigraphs/heteroData_gene_cell_Neuroblastoma_Reactome_crispr-1_5_cgp_cnv.pt')\n",
    "heterodata_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torch_geometric/edge_index.py:2007: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:55.)\n",
      "  out = torch.matmul(sparse_input, other)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  metapath_dict={\n",
       "    (gene, metapath_0, gene)=[2],\n",
       "    (cell, metapath_1, cell)=[2],\n",
       "  },\n",
       "  gene={\n",
       "    node_id=[14034],\n",
       "    names=[14034],\n",
       "    x=[14034, 3438],\n",
       "  },\n",
       "  cell={\n",
       "    node_id=[37],\n",
       "    names=[37],\n",
       "    x=[37, 1218],\n",
       "  },\n",
       "  (gene, interacts_with, gene)={ edge_index=[2, 278974] },\n",
       "  (gene, dependency_of, cell)={ edge_index=[2, 14099] },\n",
       "  (gene, rev_interacts_with, gene)={ edge_index=[2, 278974] },\n",
       "  (cell, rev_dependency_of, gene)={ edge_index=[2, 14099] },\n",
       "  (gene, metapath_0, gene)={\n",
       "    edge_index=[2, 721140],\n",
       "    edge_weight=[721140],\n",
       "  },\n",
       "  (cell, metapath_1, cell)={\n",
       "    edge_index=[2, 1369],\n",
       "    edge_weight=[1369],\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metapaths = [[('gene', 'dependency_of', 'cell'), ('cell', 'rev_dependency_of', 'gene')],\n",
    "             [('cell', 'rev_dependency_of', 'gene'), ('gene', 'dependency_of', 'cell')],\n",
    "             #[('gene', 'interacts with', 'gene')]\n",
    "             ]\n",
    "\n",
    "transform = T.AddMetaPaths(\n",
    "    metapaths=metapaths, \n",
    "    keep_same_node_type= True,\n",
    "    drop_unconnected_node_types=False, \n",
    "    weighted=True,\n",
    "    #drop_orig_edge_types=True\n",
    ")\n",
    "heterodata_obj = transform(heterodata_obj)  \n",
    "heterodata_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13034, torch.Size([1000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_disconnected_genes(hetero_data):\n",
    "    # Get the edge index for the gene-cell connection\n",
    "    gene_to_cell_edge_index = hetero_data['gene', 'dependency_of', 'cell'].edge_index\n",
    "\n",
    "    # Get the set of all gene nodes\n",
    "    total_genes = hetero_data['gene'].num_nodes\n",
    "    all_gene_nodes = torch.arange(total_genes)\n",
    "\n",
    "    # Find unique gene nodes that are connected to any cell\n",
    "    connected_gene_nodes = torch.unique(gene_to_cell_edge_index[0])\n",
    "\n",
    "    # Create a boolean mask for genes that are disconnected\n",
    "    is_disconnected = ~torch.isin(all_gene_nodes, connected_gene_nodes)\n",
    "\n",
    "    # Count disconnected genes\n",
    "    num_disconnected_genes = is_disconnected.sum().item()\n",
    "    num_connected_genes = connected_gene_nodes.size()\n",
    "    return num_disconnected_genes, num_connected_genes\n",
    "\n",
    "\n",
    "\n",
    "x = count_disconnected_genes(heterodata_obj)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique cell nodes in metapath_1: 37\n"
     ]
    }
   ],
   "source": [
    "cell_metapath_edge_index = heterodata_obj['cell', 'metapath_1', 'cell'].edge_index\n",
    "\n",
    "# Get all unique nodes involved in metapath_1\n",
    "unique_cells_in_metapath_1 = torch.unique(cell_metapath_edge_index)\n",
    "\n",
    "# Count the number of unique cell nodes in metapath_1\n",
    "num_unique_cells_in_metapath_1 = unique_cells_in_metapath_1.size(0)\n",
    "\n",
    "print(f\"Number of unique cell nodes in metapath_1: {num_unique_cells_in_metapath_1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1369"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "for i in range(37):\n",
    "    x = x +i\n",
    "\n",
    "x*2 + 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_complete_predMatrix(total_predictions: np.array,\n",
    "                                  edge_index: torch.Tensor,\n",
    "                                  index: list, columns: list) -> pd.DataFrame:\n",
    "    total_preds_df = pd.DataFrame({\"gene\":edge_index[0], \"cell\":edge_index[1], \"prob\": total_predictions})\n",
    "    # total_preds_df['gene'] = total_preds_df.gene.apply(lambda x: ppi_int2gene[x])\n",
    "    # total_preds_df['cell'] = total_preds_df.cell.apply(lambda x: int2cell[x])\n",
    "\n",
    "    dep_df = pd.DataFrame(index=index, columns=columns, dtype=float) \n",
    "    for i in range(dep_df.shape[0]):\n",
    "        tmp = total_preds_df.iloc[i*dep_df.shape[1]:(i+1)*dep_df.shape[1]]\n",
    "        dep_df.loc[tmp.cell.iloc[0], tmp.gene.values] = tmp['prob'].values\n",
    "\n",
    "    return dep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if torch.backends.mps.is_available():\n",
    "#    device = torch.device(\"mps\")\n",
    "#    x = torch.ones(1, device=device)\n",
    "#    print (x)\n",
    "# else:\n",
    "#    print (\"MPS device not found.\")\n",
    "\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/76n_grr91zn97zn1yl541y5c0000gn/T/ipykernel_65242/683908446.py:12: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  crispr_neurobl_bin = crispr_neurobl_int.applymap(lambda x: int(x < -1.5)) # binarize crispr data (-1,5 is threshold for positive dependency)\n"
     ]
    }
   ],
   "source": [
    "cells, genes = heterodata_obj['cell'].names, heterodata_obj['gene'].names\n",
    "\n",
    "cell2int = dict(zip(heterodata_obj['cell'].names, heterodata_obj['cell'].node_id.numpy()))\n",
    "gene2int = dict(zip(heterodata_obj['gene'].names, heterodata_obj['gene'].node_id.numpy()))\n",
    "dep_genes = list(set(heterodata_obj['gene', 'dependency_of', 'cell'].edge_index[0].numpy())) # all genes that have a dependency edge\n",
    "\n",
    "crispr_neurobl = pd.read_csv(\"./Data/crispr_Neuroblastoma_Reactome.csv\", index_col=0)\n",
    "crispr_neurobl_int = crispr_neurobl.copy(deep=True)\n",
    "crispr_neurobl_int.index = [cell2int[i] for i in crispr_neurobl.index]\n",
    "crispr_neurobl_int.columns = [gene2int[i] for i in crispr_neurobl.columns]\n",
    "crispr_neurobl_int = crispr_neurobl_int.loc[:, dep_genes] # only keep the genes that have a dependency edge\n",
    "crispr_neurobl_bin = crispr_neurobl_int.applymap(lambda x: int(x < -1.5)) # binarize crispr data (-1,5 is threshold for positive dependency)\n",
    "del heterodata_obj['gene'].names, heterodata_obj['cell'].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_features = [(-1,-1),256,128] #'How many hidden features for each GNN layer')\n",
    "heads = [1,1] #'Number of multiheads to use per GATlayer, must be same length as hidden features')??\n",
    "\n",
    "node_types = ['gene', 'cell']\n",
    "features_dim = {'gene': heterodata_obj['gene'].x.shape[1],\n",
    "                'cell': heterodata_obj['cell'].x.shape[1]}\n",
    "\n",
    "emb_dim = int(512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData_GNNmodel(\n",
      "  (nt1_lin): Linear(in_features=3438, out_features=512, bias=True)\n",
      "  (nt2_lin): Linear(in_features=1218, out_features=512, bias=True)\n",
      "  (nt1_emb): Embedding(14034, 512)\n",
      "  (nt2_emb): Embedding(37, 512)\n",
      "  (conv1): HeteroConv(num_relations=4)\n",
      "  (conv2): HeteroConv(num_relations=4)\n",
      "  (act_fn): ReLU()\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (classifier): LPsimple_classif()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "hetGNNmodel = HeteroData_GNNmodel(heterodata=heterodata_obj,   #model defined in GAT_model.py\n",
    "                                  node_types=node_types,\n",
    "                                  node_types_to_pred = node_types,\n",
    "                                  embedding_dim=emb_dim,\n",
    "                                  #gcn_model=args.gcn_model,\n",
    "                                  features=hidden_features,\n",
    "                                  #layer_name=args.layer_name,\n",
    "                                  heads=heads,\n",
    "                                  dropout=args.dropout,\n",
    "                                  act_fn=torch.nn.ReLU,\n",
    "                                  #lp_model=args.lp_model,\n",
    "                                  lp_model='simple',\n",
    "                                  #add_self_loops=False, #DIT MOET JE WEL TOEVOEGEN!!!\n",
    "                                  features_dim=features_dim,\n",
    "                                  aggregate='sum',\n",
    "                                  return_attention_weights=False)\n",
    "\n",
    "hetGNNmodel.to(device)\n",
    "print(hetGNNmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the full probability matrix for validation\n",
    "cls_int = heterodata_obj['cell'].node_id\n",
    "cl_probs = torch.zeros((2, len(cls_int)*len(dep_genes)), dtype=torch.long)\n",
    "    \n",
    "for i, cl in enumerate(cls_int):\n",
    "    # cl = 20\n",
    "    x_ = torch.stack((torch.tensor(dep_genes), \n",
    "                    torch.tensor([cl]*len(dep_genes))), dim=0)\n",
    "                        \n",
    "    cl_probs[:, i*len(dep_genes):(i+1)*len(dep_genes)] = x_\n",
    "full_pred_data = heterodata_obj.clone()\n",
    "full_pred_data['gene', 'dependency_of', 'cell'].edge_label_index = cl_probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "optimizer = torch.optim.Adam(hetGNNmodel.parameters(), lr=0.01)\n",
    "\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss() # Binary cross entropy loss\n",
    "best_loss = np.inf\n",
    "epoch_since_best = 0\n",
    "best_ap = 0\n",
    "best_ap_model = None\n",
    "lowest_loss = np.inf\n",
    "best_loss_model = None\n",
    "n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Split graph in train/validation\n",
    "transform_traintest = T.RandomLinkSplit(num_val=0.1,\n",
    "                                            num_test=0.2,\n",
    "                                            disjoint_train_ratio=0,\n",
    "                                            neg_sampling_ratio=3,\n",
    "                                            add_negative_train_samples=1,\n",
    "                                            edge_types=('gene', 'dependency_of', 'cell'),\n",
    "                                            rev_edge_types=('cell', 'rev_dependency_of', 'gene'),\n",
    "                                            is_undirected=True)\n",
    "\n",
    "train_data, val_data, test_data = transform_traintest(heterodata_obj)\n",
    "\n",
    "    # Define the loaders\n",
    "train_neg_sampling = True\n",
    "if train_neg_sampling:\n",
    "        train_loader = LinkNeighborLoader(data=train_data,\n",
    "                                        num_neighbors={et: [-1]*2 for et in heterodata_obj.edge_types}, \n",
    "                                        edge_label_index=((\"gene\", \"dependency_of\", \"cell\"),\n",
    "                                                            train_data[\"gene\", \"dependency_of\", \"cell\"].edge_label_index),\n",
    "                                            edge_label=train_data[\"gene\", \"dependency_of\", \"cell\"].edge_label,\n",
    "                                            batch_size=128, # how many pos per batch -> actual batch_size is (npr+1)*batch_size\n",
    "                                            directed=True, # undirected het graphs not yet supported -> that is why the reverse type is added\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=10)\n",
    "else:\n",
    "        train_loader = LinkNeighborLoader(data=train_data,\n",
    "                                        num_neighbors={et: [-1]*2 for et in heterodata_obj.edge_types}, \n",
    "                                        neg_sampling_ratio=3,\n",
    "                                        edge_label_index=((\"gene\", \"dependency_of\", \"cell\"),\n",
    "                                                            train_data[\"gene\", \"dependency_of\", \"cell\"].edge_label_index),\n",
    "                                            edge_label=train_data[\"gene\", \"dependency_of\", \"cell\"].edge_label,\n",
    "                                            batch_size=128, # how many pos per batch -> actual batch_size is (npr+1)*batch_size\n",
    "                                            directed=True, # undirected het graphs not yet supported -> that is why the reverse type is added\n",
    "                                            shuffle=True,\n",
    "                                            num_workers=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 0, 'train loss': tensor(8.7286, grad_fn=<DivBackward0>), 'val loss': tensor(0.0906), 'val auc': np.float64(0.9923499494529994), 'val ap': np.float64(0.9663413429105617), 'assay_ap': np.float64(0.6953192560913383), 'gene_ap': np.float64(0.38105405405405407), 'assay_corr_sp': np.float64(0.6189940424140652)}\n",
      "{'epoch': 1, 'train loss': tensor(0.0844, grad_fn=<DivBackward0>), 'val loss': tensor(0.0851), 'val auc': np.float64(0.9922789267615012), 'val ap': np.float64(0.9647958231696103), 'assay_ap': np.float64(0.6910976883573021), 'gene_ap': np.float64(0.38105405405405407), 'assay_corr_sp': np.float64(0.6432005676281486)}\n",
      "{'epoch': 2, 'train loss': tensor(0.0831, grad_fn=<DivBackward0>), 'val loss': tensor(0.0860), 'val auc': np.float64(0.9931337175946378), 'val ap': np.float64(0.9714735242242575), 'assay_ap': np.float64(0.7240525965604684), 'gene_ap': np.float64(0.38105405405405407), 'assay_corr_sp': np.float64(0.6614873358860662)}\n"
     ]
    }
   ],
   "source": [
    "val_ratio = 0.1\n",
    "\n",
    "# Train the model but first delete the names \n",
    "assay_ap_total, gene_ap_total = [], []\n",
    "for epoch in range(n_epochs):\n",
    "    total_train_loss = 0\n",
    "    hetGNNmodel.train()\n",
    "    \n",
    "    for sampled_data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        sampled_data.to(device)\n",
    "        \n",
    "       \n",
    "        out = hetGNNmodel(sampled_data, edge_type_label=\"gene,dependency_of,cell\")\n",
    "        \n",
    "        ground_truth = sampled_data[\"gene\", \"dependency_of\", \"cell\"].edge_label\n",
    "        loss = loss_fn(out, ground_truth) \n",
    "        total_train_loss += loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # scheduler.step()\n",
    "    ap_val, auc_val = 0, 0\n",
    "    hetGNNmodel.eval()\n",
    "    with torch.no_grad():\n",
    "        if val_ratio != 0.0:\n",
    "            val_data.to(device)\n",
    "           \n",
    "            out = hetGNNmodel(val_data, edge_type_label=\"gene,dependency_of,cell\")\n",
    "            \n",
    "            pred = torch.sigmoid(out)\n",
    "            ground_truth = val_data[\"gene\", \"dependency_of\", \"cell\"].edge_label\n",
    "            val_loss = loss_fn(out, ground_truth)\n",
    "\n",
    "            auc_val = roc_auc_score(ground_truth.cpu(), pred.cpu())\n",
    "            ap_val = average_precision_score(ground_truth.cpu(), pred.cpu())\n",
    "\n",
    "            if ap_val > best_ap:\n",
    "                best_ap = ap_val\n",
    "                best_ap_model = deepcopy(hetGNNmodel.state_dict())\n",
    "                final_epoch = epoch\n",
    "\n",
    "        full_pred_data.to(device)\n",
    "        total_preds = hetGNNmodel(data=full_pred_data, edge_type_label=\"gene,dependency_of,cell\")\n",
    "        total_preds_out = torch.sigmoid(total_preds).cpu().numpy()\n",
    "        tot_pred_deps = construct_complete_predMatrix(total_predictions=total_preds_out,\n",
    "                                                      edge_index=cl_probs,\n",
    "                                                      index=cls_int.numpy(),\n",
    "                                                      columns=dep_genes)\n",
    "\n",
    "        assay_corr = tot_pred_deps.corrwith(crispr_neurobl_int*-1, method='spearman', axis=1)  # correlation with crispr data, multiplied by -1 to reverse the direction of dependency\n",
    "        gene_ap, assay_ap = [], []\n",
    "        \n",
    "        for i, row in tot_pred_deps.iterrows():  # for each cell line\n",
    "            assay_ap.append(average_precision_score(y_true=crispr_neurobl_bin.loc[i].values,\n",
    "                                                    y_score=row.values))\n",
    "        \n",
    "        for col in tot_pred_deps.columns:  # for each gene\n",
    "            gene_ap.append(average_precision_score(y_true=crispr_neurobl_bin[col].values,\n",
    "                                                    y_score=tot_pred_deps[col].values))            \n",
    "\n",
    "        assay_ap_total.append(assay_ap)  # for all epochs\n",
    "        gene_ap_total.append(gene_ap)\n",
    "\n",
    "    print({\n",
    "        'epoch': epoch, \n",
    "        'train loss': total_train_loss/len(train_loader),\n",
    "        'val loss': val_loss, \n",
    "        'val auc': auc_val, \n",
    "        'val ap': ap_val,\n",
    "        'assay_ap': np.mean(assay_ap), \n",
    "        'gene_ap': np.mean(gene_ap),\n",
    "        'assay_corr_sp': assay_corr.mean() \n",
    "    })"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
