{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  metapath_dict={\n",
      "    (gene, metapath_0, gene)=[2],\n",
      "    (cell, metapath_1, cell)=[2],\n",
      "  },\n",
      "  gene={\n",
      "    node_id=[13398],\n",
      "    names=[13398],\n",
      "    x=[13398, 3438],\n",
      "  },\n",
      "  cell={\n",
      "    node_id=[37],\n",
      "    names=[37],\n",
      "    x=[37, 1218],\n",
      "  },\n",
      "  (gene, interacts_with, gene)={ edge_index=[2, 263122] },\n",
      "  (gene, dependency_of, cell)={ edge_index=[2, 14085] },\n",
      "  (gene, rev_interacts_with, gene)={ edge_index=[2, 263122] },\n",
      "  (cell, rev_dependency_of, gene)={ edge_index=[2, 14085] },\n",
      "  (gene, metapath_0, gene)={\n",
      "    edge_index=[2, 719373],\n",
      "    edge_weight=[719373],\n",
      "  },\n",
      "  (cell, metapath_1, cell)={\n",
      "    edge_index=[2, 1369],\n",
      "    edge_weight=[1369],\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# load multigraph\n",
    "\n",
    "path = \"./Data/multigraphs/heteroData_gene_cell_Neuroblastoma_cgp_cnv_META.pt\"\n",
    "\n",
    "new_data = torch.load(path)\n",
    "print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HeteroData(\n",
       "  gene={\n",
       "    node_id=[14034],\n",
       "    names=[14034],\n",
       "    x=[14034, 3438],\n",
       "  },\n",
       "  cell={\n",
       "    node_id=[37],\n",
       "    names=[37],\n",
       "    x=[37, 1218],\n",
       "  },\n",
       "  (gene, interacts_with, gene)={ edge_index=[2, 278974] },\n",
       "  (gene, dependency_of, cell)={ edge_index=[2, 14099] },\n",
       "  (gene, rev_interacts_with, gene)={ edge_index=[2, 278974] },\n",
       "  (cell, rev_dependency_of, gene)={ edge_index=[2, 14099] }\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./Data/multigraphs/heteroData_gene_cell_Neuroblastoma_Reactome_crispr-1_5_cgp_cnv.pt\"\n",
    "\n",
    "data_old = torch.load(path)\n",
    "\n",
    "data_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between these two graphs is that in the first graph I removed the common essential genes, whereas in the secon graph I kept them. Therefore the second graph has many more dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  metapath_dict={\n",
      "    (gene, metapath_0, gene)=[2],\n",
      "    (cell, metapath_1, cell)=[2],\n",
      "  },\n",
      "  gene={\n",
      "    node_id=[13398],\n",
      "    names=[13398],\n",
      "    x=[13398, 3438],\n",
      "  },\n",
      "  cell={\n",
      "    node_id=[37],\n",
      "    names=[37],\n",
      "    x=[37, 1218],\n",
      "  },\n",
      "  (gene, interacts_with, gene)={ edge_index=[2, 263122] },\n",
      "  (gene, dependency_of, cell)={ edge_index=[2, 14085] },\n",
      "  (gene, rev_interacts_with, gene)={ edge_index=[2, 263122] },\n",
      "  (cell, rev_dependency_of, gene)={ edge_index=[2, 14085] },\n",
      "  (gene, metapath_0, gene)={\n",
      "    edge_index=[2, 719373],\n",
      "    edge_weight=[719373],\n",
      "  },\n",
      "  (cell, metapath_1, cell)={\n",
      "    edge_index=[2, 1369],\n",
      "    edge_weight=[1369],\n",
      "  }\n",
      ")\n",
      "HeteroData(\n",
      "  gene={\n",
      "    node_id=[14034],\n",
      "    names=[14034],\n",
      "    x=[14034, 3438],\n",
      "  },\n",
      "  cell={\n",
      "    node_id=[37],\n",
      "    names=[37],\n",
      "    x=[37, 1218],\n",
      "  },\n",
      "  (gene, interacts_with, gene)={ edge_index=[2, 278974] },\n",
      "  (gene, dependency_of, cell)={ edge_index=[2, 14099] },\n",
      "  (gene, rev_interacts_with, gene)={ edge_index=[2, 278974] },\n",
      "  (cell, rev_dependency_of, gene)={ edge_index=[2, 14099] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(new_data)\n",
    "print(data_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing node types:\n",
      "  Common node types: {'gene', 'cell'}\n",
      "  Node type 'gene':\n",
      "    hdata1 has 13398 nodes, hdata2 has 14034 nodes\n",
      "    Overlap by name: 13398 nodes (100.00% of hdata1, 95.47% of hdata2)\n",
      "    Found 13393 inconsistent name-ID mappings\n",
      "    First 5 inconsistencies: [(np.str_('DCUN1D4'), 2687, 2730), (np.str_('ZNF550'), 13154, 13769), (np.str_('PDE6H'), 8290, 8720), (np.str_('RPUSD4'), 9935, 10402), (np.str_('FOXE3'), 3869, 3993)]\n",
      "  Node type 'cell':\n",
      "    hdata1 has 37 nodes, hdata2 has 37 nodes\n",
      "    Overlap by name: 37 nodes (100.00% of hdata1, 100.00% of hdata2)\n",
      "    All name-ID mappings are consistent between graphs\n",
      "\n",
      "Comparing edge types:\n",
      "  Common edge types: {('gene', 'interacts_with', 'gene'), ('gene', 'dependency_of', 'cell'), ('gene', 'rev_interacts_with', 'gene'), ('cell', 'rev_dependency_of', 'gene')}\n",
      "\n",
      "  Edge type ('gene', 'interacts_with', 'gene'):\n",
      "    hdata1 has 263122 edges, hdata2 has 278974 edges\n",
      "    Comparing edges by node names:\n",
      "      Total edges by name in hdata1: 263122\n",
      "      Total edges by name in hdata2: 278974\n",
      "      Common edges: 263122 (100.00% of hdata1, 94.32% of hdata2)\n",
      "      Edges only in hdata1: 0\n",
      "      Edges only in hdata2: 15852\n",
      "      First 3 sample edges only in hdata2: [('JCHAIN', 'V1-5'), ('TEC', 'V5-4'), ('FFAR1', 'GNAT3')]\n",
      "\n",
      "  Edge type ('gene', 'dependency_of', 'cell'):\n",
      "    hdata1 has 14085 edges, hdata2 has 14099 edges\n",
      "    Comparing edges by node names:\n",
      "      Total edges by name in hdata1: 14085\n",
      "      Total edges by name in hdata2: 14099\n",
      "      Common edges: 14085 (100.00% of hdata1, 99.90% of hdata2)\n",
      "      Edges only in hdata1: 0\n",
      "      Edges only in hdata2: 14\n",
      "      First 3 sample edges only in hdata2: [('LCE2C', 'ACH-002285'), ('LCE2C', 'ACH-000366'), ('LCE2C', 'ACH-000120')]\n",
      "\n",
      "  Edge type ('gene', 'rev_interacts_with', 'gene'):\n",
      "    hdata1 has 263122 edges, hdata2 has 278974 edges\n",
      "    Comparing edges by node names:\n",
      "      Total edges by name in hdata1: 263122\n",
      "      Total edges by name in hdata2: 278974\n",
      "      Common edges: 263122 (100.00% of hdata1, 94.32% of hdata2)\n",
      "      Edges only in hdata1: 0\n",
      "      Edges only in hdata2: 15852\n",
      "      First 3 sample edges only in hdata2: [('PCDHA8', 'DCHS1'), ('IGKV1D-33', 'IGHV2-70'), ('IGKV3D-20', 'IGHV')]\n",
      "\n",
      "  Edge type ('cell', 'rev_dependency_of', 'gene'):\n",
      "    hdata1 has 14085 edges, hdata2 has 14099 edges\n",
      "    Comparing edges by node names:\n",
      "      Total edges by name in hdata1: 14085\n",
      "      Total edges by name in hdata2: 14099\n",
      "      Common edges: 14085 (100.00% of hdata1, 99.90% of hdata2)\n",
      "      Edges only in hdata1: 0\n",
      "      Edges only in hdata2: 14\n",
      "      First 3 sample edges only in hdata2: [('ACH-001674', 'LCE2C'), ('ACH-001603', 'LCE2C'), ('ACH-000120', 'LCE2C')]\n",
      "\n",
      "Node mappings for 'gene':\n",
      "Total nodes: 13398\n",
      "\n",
      "Sample node_id to name mappings:\n",
      "  0 -> A1CF\n",
      "  1 -> A2M\n",
      "  2 -> A4GNT\n",
      "  3 -> AAAS\n",
      "  4 -> AADAT\n",
      "  5 -> AAK1\n",
      "  6 -> AAMP\n",
      "  7 -> AAR2\n",
      "  8 -> AARS1\n",
      "  9 -> AARS2\n",
      "\n",
      "Unique IDs: 13398 (Expected: 13398)\n",
      "Unique names: 13398 (Expected: 13398)\n",
      "\n",
      "Node mappings for 'cell':\n",
      "Total nodes: 37\n",
      "\n",
      "Sample node_id to name mappings:\n",
      "  0 -> ACH-000078\n",
      "  1 -> ACH-000099\n",
      "  2 -> ACH-000120\n",
      "  3 -> ACH-000149\n",
      "  4 -> ACH-000203\n",
      "  5 -> ACH-000227\n",
      "  6 -> ACH-000259\n",
      "  7 -> ACH-000260\n",
      "  8 -> ACH-000310\n",
      "  9 -> ACH-000312\n",
      "\n",
      "Unique IDs: 37 (Expected: 37)\n",
      "Unique names: 37 (Expected: 37)\n",
      "Found 2 gene nodes matching 'BRCA':\n",
      "  1178 -> BRCA1\n",
      "  1179 -> BRCA2\n",
      "\n",
      "Comparing gene nodes between graphs:\n",
      "  Graph 1: 13398 unique nodes\n",
      "  Graph 2: 14034 unique nodes\n",
      "  Common nodes: 13398 (100.00% of graph 1, 95.47% of graph 2)\n",
      "  Nodes only in graph 1: 0\n",
      "  Nodes only in graph 2: 636\n",
      "  Sample nodes only in graph 2: ['OR5H15', 'OR5J2', 'OR6C4', 'USP17L22', 'TRAV8-1']\n",
      "\n",
      "  Found 13393 nodes with inconsistent IDs between graphs\n",
      "  Sample inconsistencies (name, id1, id2): [(np.str_('DCUN1D4'), 2687, 2730), (np.str_('ZNF550'), 13154, 13769), (np.str_('PDE6H'), 8290, 8720), (np.str_('RPUSD4'), 9935, 10402), (np.str_('FOXE3'), 3869, 3993)]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from collections import defaultdict\n",
    "\n",
    "def enhanced_compare_heterodata(hdata1, hdata2):\n",
    "    \"\"\"\n",
    "    Compare two PyTorch Geometric HeteroData objects in detail,\n",
    "    checking node name-ID mappings and exact edge consistency.\n",
    "    \"\"\"\n",
    "    print(\"Comparing node types:\")\n",
    "    node_types1 = set(hdata1.node_types)\n",
    "    node_types2 = set(hdata2.node_types)\n",
    "    common_node_types = node_types1 & node_types2\n",
    "    print(\"  Common node types:\", common_node_types)\n",
    "    \n",
    "    # Dictionary to store node_id to name mappings for both graphs\n",
    "    id_to_name1 = defaultdict(dict)\n",
    "    id_to_name2 = defaultdict(dict)\n",
    "    name_to_id1 = defaultdict(dict)\n",
    "    name_to_id2 = defaultdict(dict)\n",
    "    \n",
    "    # First, extract node mappings (ID to name and name to ID)\n",
    "    for nt in common_node_types:\n",
    "        if hasattr(hdata1[nt], \"node_id\") and hasattr(hdata1[nt], \"names\") and \\\n",
    "           hasattr(hdata2[nt], \"node_id\") and hasattr(hdata2[nt], \"names\"):\n",
    "            \n",
    "            # Extract IDs and names\n",
    "            ids1 = hdata1[nt].node_id\n",
    "            names1 = hdata1[nt].names\n",
    "            ids2 = hdata2[nt].node_id\n",
    "            names2 = hdata2[nt].names\n",
    "            \n",
    "            # Convert to Python lists if they're tensors\n",
    "            ids1_list = ids1.tolist() if isinstance(ids1, torch.Tensor) else ids1\n",
    "            names1_list = names1.tolist() if isinstance(names1, torch.Tensor) else names1\n",
    "            ids2_list = ids2.tolist() if isinstance(ids2, torch.Tensor) else ids2\n",
    "            names2_list = names2.tolist() if isinstance(names2, torch.Tensor) else names2\n",
    "            \n",
    "            # Create mappings\n",
    "            for i, name in zip(ids1_list, names1_list):\n",
    "                id_to_name1[nt][i] = name\n",
    "                name_to_id1[nt][name] = i\n",
    "                \n",
    "            for i, name in zip(ids2_list, names2_list):\n",
    "                id_to_name2[nt][i] = name\n",
    "                name_to_id2[nt][name] = i\n",
    "            \n",
    "            # Compare by names instead of IDs\n",
    "            names1_set = set(names1_list)\n",
    "            names2_set = set(names2_list)\n",
    "            overlap = names1_set & names2_set\n",
    "            \n",
    "            print(f\"  Node type '{nt}':\")\n",
    "            print(f\"    hdata1 has {len(names1_set)} nodes, hdata2 has {len(names2_set)} nodes\")\n",
    "            print(f\"    Overlap by name: {len(overlap)} nodes ({len(overlap)/len(names1_set)*100:.2f}% of hdata1, {len(overlap)/len(names2_set)*100:.2f}% of hdata2)\")\n",
    "            \n",
    "            # Check if name-ID mappings are consistent\n",
    "            inconsistent_mappings = []\n",
    "            for name in overlap:\n",
    "                id1 = name_to_id1[nt][name]\n",
    "                id2 = name_to_id2[nt][name]\n",
    "                if id1 != id2:\n",
    "                    inconsistent_mappings.append((name, id1, id2))\n",
    "            \n",
    "            if inconsistent_mappings:\n",
    "                print(f\"    Found {len(inconsistent_mappings)} inconsistent name-ID mappings\")\n",
    "                print(f\"    First 5 inconsistencies: {inconsistent_mappings[:5]}\")\n",
    "            else:\n",
    "                print(\"    All name-ID mappings are consistent between graphs\")\n",
    "        else:\n",
    "            print(f\"  Node type '{nt}' is missing node_id or names attributes in one or both graphs\")\n",
    "    \n",
    "    print(\"\\nComparing edge types:\")\n",
    "    edge_types1 = set(hdata1.edge_types) if hasattr(hdata1, \"edge_types\") else set(hdata1.keys()) - set(hdata1.node_types)\n",
    "    edge_types2 = set(hdata2.edge_types) if hasattr(hdata2, \"edge_types\") else set(hdata2.keys()) - set(hdata2.node_types)\n",
    "    common_edge_types = edge_types1 & edge_types2\n",
    "    print(\"  Common edge types:\", common_edge_types)\n",
    "    \n",
    "    for et in common_edge_types:\n",
    "        src_type, edge_type, dst_type = et\n",
    "        \n",
    "        if hasattr(hdata1[et], \"edge_index\") and hasattr(hdata2[et], \"edge_index\"):\n",
    "            edges1 = hdata1[et].edge_index\n",
    "            edges2 = hdata2[et].edge_index\n",
    "            \n",
    "            num_edges1 = edges1.shape[1] if isinstance(edges1, torch.Tensor) else len(edges1)\n",
    "            num_edges2 = edges2.shape[1] if isinstance(edges2, torch.Tensor) else len(edges2)\n",
    "            \n",
    "            print(f\"\\n  Edge type {et}:\")\n",
    "            print(f\"    hdata1 has {num_edges1} edges, hdata2 has {num_edges2} edges\")\n",
    "            \n",
    "            # Convert edge indices to edges with names\n",
    "            if (src_type in name_to_id1 and dst_type in name_to_id1 and \n",
    "                src_type in name_to_id2 and dst_type in name_to_id2):\n",
    "                \n",
    "                # Convert edge indices to lists\n",
    "                edges1_list = edges1.t().tolist() if isinstance(edges1, torch.Tensor) else edges1\n",
    "                edges2_list = edges2.t().tolist() if isinstance(edges2, torch.Tensor) else edges2\n",
    "                \n",
    "                # Convert node IDs to node names for edges\n",
    "                named_edges1 = set()\n",
    "                for src_id, dst_id in edges1_list:\n",
    "                    if src_id in id_to_name1[src_type] and dst_id in id_to_name1[dst_type]:\n",
    "                        src_name = id_to_name1[src_type][src_id]\n",
    "                        dst_name = id_to_name1[dst_type][dst_id]\n",
    "                        named_edges1.add((src_name, dst_name))\n",
    "                    \n",
    "                named_edges2 = set()\n",
    "                for src_id, dst_id in edges2_list:\n",
    "                    if src_id in id_to_name2[src_type] and dst_id in id_to_name2[dst_type]:\n",
    "                        src_name = id_to_name2[src_type][src_id]\n",
    "                        dst_name = id_to_name2[dst_type][dst_id]\n",
    "                        named_edges2.add((src_name, dst_name))\n",
    "                \n",
    "                # Compare exact edges by name\n",
    "                common_edges = named_edges1 & named_edges2\n",
    "                only_in_1 = named_edges1 - named_edges2\n",
    "                only_in_2 = named_edges2 - named_edges1\n",
    "                \n",
    "                print(f\"    Comparing edges by node names:\")\n",
    "                print(f\"      Total edges by name in hdata1: {len(named_edges1)}\")\n",
    "                print(f\"      Total edges by name in hdata2: {len(named_edges2)}\")\n",
    "                print(f\"      Common edges: {len(common_edges)} ({len(common_edges)/len(named_edges1)*100:.2f}% of hdata1, {len(common_edges)/len(named_edges2)*100:.2f}% of hdata2)\")\n",
    "                print(f\"      Edges only in hdata1: {len(only_in_1)}\")\n",
    "                print(f\"      Edges only in hdata2: {len(only_in_2)}\")\n",
    "                \n",
    "                if len(only_in_1) > 0:\n",
    "                    print(f\"      First 3 sample edges only in hdata1: {list(only_in_1)[:3]}\")\n",
    "                if len(only_in_2) > 0:\n",
    "                    print(f\"      First 3 sample edges only in hdata2: {list(only_in_2)[:3]}\")\n",
    "            else:\n",
    "                print(f\"    Cannot compare edges by name for {et} due to missing name mappings\")\n",
    "        else:\n",
    "            print(f\"  Edge type {et}: Edge index attribute not found in one of the objects\")\n",
    "            \n",
    "    return id_to_name1, name_to_id1, id_to_name2, name_to_id2\n",
    "\n",
    "\n",
    "def print_node_mappings(hdata, node_type, limit=10):\n",
    "    \"\"\"\n",
    "    Print the node ID to name mappings for a specific node type in a HeteroData object.\n",
    "    \n",
    "    Args:\n",
    "        hdata: PyTorch Geometric HeteroData object\n",
    "        node_type: The node type to print mappings for (e.g., 'gene', 'cell')\n",
    "        limit: Maximum number of mappings to print\n",
    "    \"\"\"\n",
    "    if not hasattr(hdata[node_type], \"node_id\") or not hasattr(hdata[node_type], \"names\"):\n",
    "        print(f\"Node type '{node_type}' is missing node_id or names attributes\")\n",
    "        return\n",
    "    \n",
    "    node_ids = hdata[node_type].node_id\n",
    "    names = hdata[node_type].names\n",
    "    \n",
    "    # Convert to Python lists if they're tensors\n",
    "    node_ids_list = node_ids.tolist() if isinstance(node_ids, torch.Tensor) else node_ids\n",
    "    names_list = names.tolist() if isinstance(names, torch.Tensor) else names\n",
    "    \n",
    "    print(f\"\\nNode mappings for '{node_type}':\")\n",
    "    print(f\"Total nodes: {len(node_ids_list)}\")\n",
    "    \n",
    "    print(\"\\nSample node_id to name mappings:\")\n",
    "    for i, (node_id, name) in enumerate(zip(node_ids_list, names_list)):\n",
    "        if i >= limit:\n",
    "            break\n",
    "        print(f\"  {node_id} -> {name}\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    unique_ids = set(node_ids_list)\n",
    "    unique_names = set(names_list)\n",
    "    \n",
    "    print(f\"\\nUnique IDs: {len(unique_ids)} (Expected: {len(node_ids_list)})\")\n",
    "    print(f\"Unique names: {len(unique_names)} (Expected: {len(names_list)})\")\n",
    "    \n",
    "    if len(unique_ids) < len(node_ids_list):\n",
    "        print(\"WARNING: Duplicate node IDs detected!\")\n",
    "    \n",
    "    if len(unique_names) < len(names_list):\n",
    "        print(\"WARNING: Duplicate node names detected!\")\n",
    "\n",
    "\n",
    "def find_node_by_name(hdata, node_type, name_pattern):\n",
    "    \"\"\"\n",
    "    Find nodes in a HeteroData object where the name contains the given pattern.\n",
    "    \n",
    "    Args:\n",
    "        hdata: PyTorch Geometric HeteroData object\n",
    "        node_type: The node type to search in (e.g., 'gene', 'cell')\n",
    "        name_pattern: A string pattern to search for in node names\n",
    "    \"\"\"\n",
    "    if not hasattr(hdata[node_type], \"node_id\") or not hasattr(hdata[node_type], \"names\"):\n",
    "        print(f\"Node type '{node_type}' is missing node_id or names attributes\")\n",
    "        return []\n",
    "    \n",
    "    node_ids = hdata[node_type].node_id\n",
    "    names = hdata[node_type].names\n",
    "    \n",
    "    # Convert to Python lists if they're tensors\n",
    "    node_ids_list = node_ids.tolist() if isinstance(node_ids, torch.Tensor) else node_ids\n",
    "    names_list = names.tolist() if isinstance(names, torch.Tensor) else names\n",
    "    \n",
    "    matching_nodes = []\n",
    "    for node_id, name in zip(node_ids_list, names_list):\n",
    "        if name_pattern.lower() in str(name).lower():\n",
    "            matching_nodes.append((node_id, name))\n",
    "    \n",
    "    print(f\"Found {len(matching_nodes)} {node_type} nodes matching '{name_pattern}':\")\n",
    "    for i, (node_id, name) in enumerate(matching_nodes[:10]):\n",
    "        print(f\"  {node_id} -> {name}\")\n",
    "    \n",
    "    if len(matching_nodes) > 10:\n",
    "        print(f\"  ... and {len(matching_nodes) - 10} more\")\n",
    "    \n",
    "    return matching_nodes\n",
    "\n",
    "\n",
    "def compare_nodes_between_graphs(hdata1, hdata2, node_type):\n",
    "    \"\"\"\n",
    "    Compare nodes between two HeteroData objects for a specific node type.\n",
    "    \n",
    "    Args:\n",
    "        hdata1: First PyTorch Geometric HeteroData object\n",
    "        hdata2: Second PyTorch Geometric HeteroData object\n",
    "        node_type: The node type to compare (e.g., 'gene', 'cell')\n",
    "    \"\"\"\n",
    "    if (not hasattr(hdata1[node_type], \"node_id\") or not hasattr(hdata1[node_type], \"names\") or \n",
    "        not hasattr(hdata2[node_type], \"node_id\") or not hasattr(hdata2[node_type], \"names\")):\n",
    "        print(f\"Node type '{node_type}' is missing node_id or names attributes in one or both graphs\")\n",
    "        return\n",
    "    \n",
    "    # Extract IDs and names\n",
    "    ids1 = hdata1[node_type].node_id\n",
    "    names1 = hdata1[node_type].names\n",
    "    ids2 = hdata2[node_type].node_id\n",
    "    names2 = hdata2[node_type].names\n",
    "    \n",
    "    # Convert to Python lists if they're tensors\n",
    "    ids1_list = ids1.tolist() if isinstance(ids1, torch.Tensor) else ids1\n",
    "    names1_list = names1.tolist() if isinstance(names1, torch.Tensor) else names1\n",
    "    ids2_list = ids2.tolist() if isinstance(ids2, torch.Tensor) else ids2\n",
    "    names2_list = names2.tolist() if isinstance(names2, torch.Tensor) else names2\n",
    "    \n",
    "    # Create name sets for comparison\n",
    "    names1_set = set(names1_list)\n",
    "    names2_set = set(names2_list)\n",
    "    \n",
    "    common_names = names1_set & names2_set\n",
    "    only_in_1 = names1_set - names2_set\n",
    "    only_in_2 = names2_set - names1_set\n",
    "    \n",
    "    print(f\"\\nComparing {node_type} nodes between graphs:\")\n",
    "    print(f\"  Graph 1: {len(names1_set)} unique nodes\")\n",
    "    print(f\"  Graph 2: {len(names2_set)} unique nodes\")\n",
    "    print(f\"  Common nodes: {len(common_names)} ({len(common_names)/len(names1_set)*100:.2f}% of graph 1, {len(common_names)/len(names2_set)*100:.2f}% of graph 2)\")\n",
    "    print(f\"  Nodes only in graph 1: {len(only_in_1)}\")\n",
    "    print(f\"  Nodes only in graph 2: {len(only_in_2)}\")\n",
    "    \n",
    "    if len(only_in_1) > 0:\n",
    "        print(f\"  Sample nodes only in graph 1: {list(only_in_1)[:5]}\")\n",
    "    if len(only_in_2) > 0:\n",
    "        print(f\"  Sample nodes only in graph 2: {list(only_in_2)[:5]}\")\n",
    "    \n",
    "    # Create mappings for ID consistency check\n",
    "    name_to_id1 = {name: id for id, name in zip(ids1_list, names1_list)}\n",
    "    name_to_id2 = {name: id for id, name in zip(ids2_list, names2_list)}\n",
    "    \n",
    "    # Check for ID consistency for common names\n",
    "    inconsistent = []\n",
    "    for name in common_names:\n",
    "        if name_to_id1[name] != name_to_id2[name]:\n",
    "            inconsistent.append((name, name_to_id1[name], name_to_id2[name]))\n",
    "    \n",
    "    if inconsistent:\n",
    "        print(f\"\\n  Found {len(inconsistent)} nodes with inconsistent IDs between graphs\")\n",
    "        print(f\"  Sample inconsistencies (name, id1, id2): {inconsistent[:5]}\")\n",
    "    else:\n",
    "        print(\"\\n  All common nodes have consistent IDs between graphs\")\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "id_to_name1, name_to_id1, id_to_name2, name_to_id2 = enhanced_compare_heterodata(new_data, data_old)\n",
    "print_node_mappings(new_data, 'gene')\n",
    "print_node_mappings(data_old, 'cell')\n",
    "find_node_by_name(new_data, 'gene', 'BRCA')\n",
    "compare_nodes_between_graphs(new_data, data_old, 'gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scalar() argument 1 must be numpy.dtype, not numpy.dtypes.StrDType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./Data/multigraphs/heteroData_gene_cell_All_cgp_cnv_META.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(new_data)\n",
      "File \u001b[0;32m~/Downloads/MSc Bioinformatics/Year 2/Thesis/GIT_HetGNN/env/lib/python3.11/site-packages/torch/serialization.py:1025\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1024\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1025\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1031\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Downloads/MSc Bioinformatics/Year 2/Thesis/GIT_HetGNN/env/lib/python3.11/site-packages/torch/serialization.py:1446\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1444\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1445\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1446\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1449\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1450\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1451\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: scalar() argument 1 must be numpy.dtype, not numpy.dtypes.StrDType"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"./Data/multigraphs/heteroData_gene_cell_All_cgp_cnv_META.pt\"\n",
    "\n",
    "new_data = torch.load(path)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n"
     ]
    }
   ],
   "source": [
    "#print numpy version\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jovanafilipovic/Downloads/MSc Bioinformatics/Year 2/Thesis/GIT_HetGNN/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy              1.25.1\n",
      "torch              2.3.1\n",
      "torch_cluster      1.6.3\n",
      "torch-geometric    2.6.1\n",
      "torch_scatter      2.1.2\n",
      "torch_sparse       0.6.18\n",
      "torch_spline_conv  1.2.2\n",
      "torchvision        0.18.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep numpy\n",
    "!pip list | grep torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
